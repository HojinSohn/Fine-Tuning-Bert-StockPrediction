{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0e56f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   polarity          id                          date     query  \\\n",
      "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
      "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
      "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
      "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
      "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
      "\n",
      "              user                                               text  \n",
      "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
      "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
      "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
      "4           Karoli  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('sentiment_text_data.csv', encoding='latin-1', header=None, \n",
    "                   names=['polarity', 'id', 'date', 'query', 'user', 'text'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e46a12ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['id', 'date', 'query', 'user'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fbb6685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   polarity                                               text\n",
      "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1         0  is upset that he can't update his Facebook by ...\n",
      "2         0  @Kenichan I dived many times for the ball. Man...\n",
      "3         0    my whole body feels itchy and like its on fire \n",
      "4         0  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c811954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9493da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"@\\S+\", \"\", text)     # Remove mentions\n",
    "    text = re.sub(r\"#\\S+\", \"\", text)     # Remove hashtags\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove non-alphabetical \n",
    "\n",
    "    return text.lower()  # Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea36593",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "774a0b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sohn31/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763c62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c53a425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   polarity                                               text\n",
      "0         0  awww thats bummer shoulda got david carr third...\n",
      "1         0  upset cant update facebook texting might cry r...\n",
      "2         0  dived many times ball managed save rest go bounds\n",
      "3         0                   whole body feels itchy like fire\n",
      "4         0                           behaving im mad cant see\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "825fe49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         polarity                                               text\n",
      "1599900         4  goal stocks like mtxx help one person avoided ...\n",
      "1599901         4           thats im thinking knock water satisfying\n",
      "1599902         4  yeah remotes car couldnt find mine didnt know ...\n",
      "1599903         4  post le mans pics didnt really shoot much bit ...\n",
      "1599904         4                                       traitor love\n",
      "...           ...                                                ...\n",
      "1599995         4                      woke school best feeling ever\n",
      "1599996         4            thewdbcom cool hear old walt interviews\n",
      "1599997         4                    ready mojo makeover ask details\n",
      "1599998         4  happy th birthday boo alll time tupac amaru sh...\n",
      "1599999         4                                              happy\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.tail(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X = data['text']\n",
    "y = data['polarity'].apply(lambda x: 1 if x == 4 else (0 if x == 0 else 2))  # Mapping: 1 = positive, 0 = negative, 2 = neutral\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentimentAnalysis",
   "language": "python",
   "name": "sentimentanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
